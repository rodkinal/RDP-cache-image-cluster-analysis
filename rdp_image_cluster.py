#!/usr/bin/env python3
"""
ğŸ¯ CLUSTERING COMPLETO DE IMÃGENES
===================================

Script unificado que:
1. Lee tiles de imÃ¡genes desde una carpeta especificada
2. Realiza anÃ¡lisis exploratorio con grÃ¡ficos
3. Permite al usuario elegir el nÃºmero de clusters
4. Organiza las imÃ¡genes en carpetas separadas

Uso:
    python complete_clustering.py <ruta_carpeta_tiles>

Ejemplo:
    python complete_clustering.py Raw_data
    python complete_clustering.py "C:/Users/Usuario/MisDatos"

Autor: Rodkinal
Fecha: 2025
"""

import os
import sys
import shutil
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.manifold import TSNE
from collections import Counter
import pandas as pd
from datetime import datetime
import argparse
import warnings
warnings.filterwarnings('ignore')

# Configurar matplotlib para mejor visualizaciÃ³n
plt.style.use('default')
sns.set_palette("husl")

class CompleteImageClustering:
    """
    Sistema completo de clustering de imÃ¡genes con anÃ¡lisis y visualizaciÃ³n
    """
    
    def __init__(self, data_folder, tsne_samples=5000):
        self.data_folder = data_folder
        self.tsne_samples = tsne_samples
        self.image_paths = []
        self.image_features = []
        self.image_names = []
        self.folder_labels = []
        self.cluster_labels = []
        self.pca_features = None
        self.scaler = None
        self.pca_model = None
        
        # Verificar que la carpeta existe
        if not os.path.exists(data_folder):
            raise FileNotFoundError(f"âŒ La carpeta {data_folder} no existe")
    
    def discover_data_structure(self):
        """
        Descubre y analiza la estructura de datos
        """
        print(f"ğŸ” EXPLORANDO ESTRUCTURA DE DATOS")
        print("=" * 50)
        print(f"ğŸ“ Carpeta base: {self.data_folder}")
        
        # Buscar subcarpetas con imÃ¡genes
        folders_found = []
        total_images = 0
        
        for item in os.listdir(self.data_folder):
            item_path = os.path.join(self.data_folder, item)
            if os.path.isdir(item_path):
                # Buscar imÃ¡genes BMP en la subcarpeta
                image_files = [f for f in os.listdir(item_path) 
                              if f.lower().endswith(('.bmp', '.png', '.jpg', '.jpeg'))]
                
                if len(image_files) > 0:
                    folders_found.append((item, len(image_files)))
                    total_images += len(image_files)
                    print(f"  ğŸ“‚ {item}: {len(image_files):,} imÃ¡genes")
        
        if not folders_found:
            # Si no hay subcarpetas, buscar directamente en la carpeta base
            image_files = [f for f in os.listdir(self.data_folder) 
                          if f.lower().endswith(('.bmp', '.png', '.jpg', '.jpeg'))]
            if len(image_files) > 0:
                folders_found.append((".", len(image_files)))
                total_images = len(image_files)
                print(f"  ğŸ“‚ Carpeta raÃ­z: {len(image_files):,} imÃ¡genes")
        
        if total_images == 0:
            raise ValueError("âŒ No se encontraron imÃ¡genes en la carpeta especificada")
        
        print(f"\nğŸ“Š RESUMEN:")
        print(f"  ğŸ—‚ï¸ Carpetas con imÃ¡genes: {len(folders_found)}")
        print(f"  ğŸ–¼ï¸ Total de imÃ¡genes: {total_images:,}")
        
        # EstimaciÃ³n de tiempo
        time_estimate = total_images / 200  # Aproximadamente 200 imÃ¡genes por segundo
        print(f"  â±ï¸ Tiempo estimado de procesamiento: {time_estimate/60:.1f} minutos")
        
        return folders_found, total_images
    
    def load_images(self, max_images_per_folder=None, sample_size=(64, 64)):
        """
        Carga todas las imÃ¡genes para anÃ¡lisis
        """
        print(f"\nğŸ”„ CARGANDO IMÃGENES")
        print("=" * 30)
        
        folders_found, _ = self.discover_data_structure()
        
        for folder_name, img_count in folders_found:
            if folder_name == ".":
                folder_path = self.data_folder
            else:
                folder_path = os.path.join(self.data_folder, folder_name)
            
            # Obtener archivos de imagen
            image_files = [f for f in os.listdir(folder_path) 
                          if f.lower().endswith(('.bmp', '.png', '.jpg', '.jpeg'))]
            
            if max_images_per_folder:
                image_files = image_files[:max_images_per_folder]
            
            print(f"  ğŸ“‚ {folder_name}: procesando {len(image_files)} imÃ¡genes...")
            
            for i, img_file in enumerate(image_files):
                img_path = os.path.join(folder_path, img_file)
                try:
                    # Cargar y procesar imagen
                    img = Image.open(img_path)
                    
                    # Manejar diferentes modos de imagen
                    if img.mode == 'RGBA':
                        background = Image.new('RGB', img.size, (255, 255, 255))
                        background.paste(img, mask=img.split()[-1])
                        img = background
                    elif img.mode != 'RGB':
                        img = img.convert('RGB')
                    
                    img = img.resize(sample_size)
                    img_array = np.array(img)
                    
                    # Extraer caracterÃ­sticas de color
                    features = self._extract_color_features(img_array)
                    
                    self.image_paths.append(img_path)
                    self.image_features.append(features)
                    self.image_names.append(img_file)
                    self.folder_labels.append(folder_name)
                    
                    # Mostrar progreso cada 1000 imÃ¡genes
                    if (i + 1) % 1000 == 0:
                        print(f"    ğŸ“‹ Procesadas {i + 1} imÃ¡genes...")
                    
                except Exception as e:
                    print(f"    âŒ Error cargando {img_file}: {e}")
                    continue
        
        self.image_features = np.array(self.image_features)
        print(f"\nâœ… Cargadas {len(self.image_features):,} imÃ¡genes exitosamente")
        print(f"ğŸ“Š Dimensiones de caracterÃ­sticas: {self.image_features.shape}")
    
    def _extract_color_features(self, img_array):
        """
        Extrae caracterÃ­sticas completas de color de una imagen
        """
        features = []
        
        # 1. EstadÃ­sticas bÃ¡sicas por canal RGB
        for channel in range(3):
            channel_data = img_array[:, :, channel].flatten()
            features.extend([
                np.mean(channel_data),           # Media
                np.std(channel_data),            # DesviaciÃ³n estÃ¡ndar
                np.percentile(channel_data, 25), # Q1
                np.percentile(channel_data, 75), # Q3
                np.median(channel_data),         # Mediana
            ])
        
        # 2. Color dominante (promedio de toda la imagen)
        dominant_color = np.mean(img_array.reshape(-1, 3), axis=0)
        features.extend(dominant_color)
        
        # 3. Brillo general
        brightness = np.mean(img_array)
        features.append(brightness)
        
        # 4. Contraste (desviaciÃ³n estÃ¡ndar del brillo)
        gray = np.mean(img_array, axis=2)
        contrast = np.std(gray)
        features.append(contrast)
        
        # 5. ConversiÃ³n a HSV para caracterÃ­sticas adicionales
        img_hsv = plt.cm.colors.rgb_to_hsv(img_array / 255.0)
        features.extend([
            np.mean(img_hsv[:, :, 0]),  # Hue promedio
            np.mean(img_hsv[:, :, 1]),  # SaturaciÃ³n promedio
            np.mean(img_hsv[:, :, 2]),  # Valor promedio
        ])
        
        return np.array(features)
    
    def prepare_data_and_analyze_clusters(self):
        """
        Prepara los datos y analiza directamente los clusters Ã³ptimos
        """
        print(f"\nğŸ“Š PREPARANDO DATOS Y ANALIZANDO CLUSTERS")
        print("=" * 50)
        
        if len(self.image_features) == 0:
            print("âŒ No hay imÃ¡genes cargadas")
            return
        
        # 1. Normalizar caracterÃ­sticas (StandardScaler)
        print("ğŸ”§ Normalizando caracterÃ­sticas de color...")
        scaler = StandardScaler()
        scaled_features = scaler.fit_transform(self.image_features)
        print(f"   âœ… CaracterÃ­sticas normalizadas (media=0, std=1)")
        print(f"   ğŸ“Š Forma original: {self.image_features.shape}")
        print(f"   ğŸ“Š Rango pre-normalizaciÃ³n: [{self.image_features.min():.2f}, {self.image_features.max():.2f}]")
        print(f"   ğŸ“Š Rango post-normalizaciÃ³n: [{scaled_features.min():.2f}, {scaled_features.max():.2f}]")
        
        # 2. PCA para reducciÃ³n de dimensionalidad
        print("ğŸ”§ Aplicando reducciÃ³n de dimensionalidad (PCA)...")
        max_components = min(scaled_features.shape[0], scaled_features.shape[1])
        n_components = min(10, max_components - 1)
        
        pca = PCA(n_components=n_components)
        pca_features = pca.fit_transform(scaled_features)
        
        self.pca_features = pca_features
        self.scaler = scaler
        self.pca_model = pca
        
        print(f"   âœ… PCA aplicado con {n_components} componentes")
        print(f"   ğŸ“Š Varianza explicada total: {pca.explained_variance_ratio_.sum():.3f}")
        print(f"   ğŸ“Š Dimensiones finales: {pca_features.shape}")
        
        # AnÃ¡lisis directo de clusters Ã³ptimos
        optimal_k = self._analyze_optimal_clusters(pca_features)
        
        return optimal_k
    
    def prepare_data_for_analysis_only(self):
        """
        Prepara los datos y muestra anÃ¡lisis de clusters para modo --only-analysis
        """
        print(f"\nğŸ“Š PREPARANDO DATOS Y ANALIZANDO CLUSTERS")
        print("=" * 50)
        
        if len(self.image_features) == 0:
            print("âŒ No hay imÃ¡genes cargadas")
            return
        
        # 1. Normalizar caracterÃ­sticas (StandardScaler)
        print("ğŸ”§ Normalizando caracterÃ­sticas de color...")
        scaler = StandardScaler()
        scaled_features = scaler.fit_transform(self.image_features)
        print(f"   âœ… CaracterÃ­sticas normalizadas (media=0, std=1)")
        print(f"   ğŸ“Š Forma original: {self.image_features.shape}")
        print(f"   ğŸ“Š Rango pre-normalizaciÃ³n: [{self.image_features.min():.2f}, {self.image_features.max():.2f}]")
        print(f"   ğŸ“Š Rango post-normalizaciÃ³n: [{scaled_features.min():.2f}, {scaled_features.max():.2f}]")
        
        # 2. PCA para reducciÃ³n de dimensionalidad
        print("ğŸ”§ Aplicando reducciÃ³n de dimensionalidad (PCA)...")
        max_components = min(scaled_features.shape[0], scaled_features.shape[1])
        n_components = min(10, max_components - 1)
        
        pca = PCA(n_components=n_components)
        pca_features = pca.fit_transform(scaled_features)
        
        self.pca_features = pca_features
        self.scaler = scaler
        self.pca_model = pca
        
        print(f"   âœ… PCA aplicado con {n_components} componentes")
        print(f"   ğŸ“Š Varianza explicada total: {pca.explained_variance_ratio_.sum():.3f}")
        print(f"   ğŸ“Š Dimensiones finales: {pca_features.shape}")
        
        # AnÃ¡lisis de clusters Ã³ptimos (igual que el modo completo)
        optimal_k = self._analyze_optimal_clusters(pca_features)
        
        return optimal_k

    
    def _analyze_optimal_clusters(self, pca_features, max_k=15):
        """
        Analiza el nÃºmero Ã³ptimo de clusters
        """
        print(f"\nğŸ¯ ANÃLISIS DE CLUSTERS Ã“PTIMOS")
        print("-" * 40)
        
        k_range = range(2, min(max_k + 1, len(pca_features) // 2))
        inertias = []
        silhouette_scores = []
        
        print("Calculando mÃ©tricas para diferentes valores de k...")
        
        for k in k_range:
            # K-means
            #kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')
            kmeans = KMeans(n_clusters=k, n_init='auto', algorithm="elkan")

            cluster_labels = kmeans.fit_predict(pca_features)
            
            # MÃ©tricas
            inertia = kmeans.inertia_
            silhouette = silhouette_score(pca_features, cluster_labels)
            
            inertias.append(inertia)
            silhouette_scores.append(silhouette)
            
            print(f"  k={k}: Silhouette={silhouette:.3f}, Inertia={inertia:.1f}")
        
        # Encontrar k Ã³ptimo (mejor silhouette score)
        optimal_idx = np.argmax(silhouette_scores)
        optimal_k = list(k_range)[optimal_idx]
        best_silhouette = silhouette_scores[optimal_idx]
        
        print(f"\nğŸ† NÃºmero Ã³ptimo de clusters: {optimal_k}")
        print(f"ğŸ“Š Mejor Silhouette Score: {best_silhouette:.3f}")
        
        # Crear grÃ¡fico de anÃ¡lisis de clusters (sin t-SNE)
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # GrÃ¡fico del codo (Elbow method)
        ax1.plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)
        ax1.set_xlabel('NÃºmero de Clusters (k)')
        ax1.set_ylabel('Inertia (Within-cluster sum of squares)')
        ax1.set_title('ğŸ“ˆ MÃ©todo del Codo')
        ax1.grid(True, alpha=0.3)
        ax1.axvline(x=optimal_k, color='red', linestyle='--', alpha=0.7, label=f'Ã“ptimo k={optimal_k}')
        ax1.legend()
        
        # Silhouette score
        ax2.plot(k_range, silhouette_scores, 'ro-', linewidth=2, markersize=8)
        ax2.set_xlabel('NÃºmero de Clusters (k)')
        ax2.set_ylabel('Silhouette Score')
        ax2.set_title('ğŸ“Š AnÃ¡lisis Silhouette')
        ax2.grid(True, alpha=0.3)
        ax2.axvline(x=optimal_k, color='red', linestyle='--', alpha=0.7, label=f'Ã“ptimo k={optimal_k}')
        ax2.axhline(y=best_silhouette, color='green', linestyle=':', alpha=0.7, label=f'Score={best_silhouette:.3f}')
        ax2.legend()
        
        plt.tight_layout()
        
        # Guardar grÃ¡fico
        cluster_analysis_path = "cluster_analysis.png"
        plt.savefig(cluster_analysis_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ’¾ AnÃ¡lisis de clusters guardado: {cluster_analysis_path}")
        
        plt.show()
        
        return optimal_k
    
    def ask_user_clusters(self, suggested_k):
        """
        Pregunta al usuario cuÃ¡ntos clusters quiere
        """
        print(f"\nğŸ¤” SELECCIÃ“N DE CLUSTERS")
        print("=" * 30)
        print(f"ğŸ’¡ El anÃ¡lisis sugiere {suggested_k} clusters como Ã³ptimo")
        print("ğŸ“Š Puedes ver los grÃ¡ficos generados para tomar tu decisiÃ³n")
        
        while True:
            try:
                user_input = input(f"\nÂ¿CuÃ¡ntos clusters quieres usar? (2-20, Enter para usar {suggested_k}): ").strip()
                
                if user_input == "":
                    return suggested_k
                
                k = int(user_input)
                if 2 <= k <= 20:
                    return k
                else:
                    print("âŒ El nÃºmero debe estar entre 2 y 20")
                    
            except ValueError:
                print("âŒ Por favor ingresa un nÃºmero vÃ¡lido")
    
    def perform_clustering(self, n_clusters):
        """
        Realiza el clustering final
        """
        print(f"\nğŸ¯ CLUSTERING FINAL CON {n_clusters} CLUSTERS")
        print("=" * 50)
        
        if self.pca_features is None:
            print("âŒ Primero ejecuta el anÃ¡lisis exploratorio")
            return None
        
        # Clustering
        kmeans = KMeans(n_clusters=n_clusters, n_init="auto", algorithm="elkan")
        self.cluster_labels = kmeans.fit_predict(self.pca_features)
        
        # Calcular mÃ©tricas
        silhouette = silhouette_score(self.pca_features, self.cluster_labels)
        
        # EstadÃ­sticas
        cluster_counts = Counter(self.cluster_labels)
        print(f"ğŸ“Š Silhouette Score: {silhouette:.3f}")
        print(f"ğŸ“Š DistribuciÃ³n de clusters:")
        
        for i in range(n_clusters):
            count = cluster_counts.get(i, 0)
            percentage = (count / len(self.cluster_labels)) * 100
            print(f"  ğŸ¯ Cluster {i}: {count:,} imÃ¡genes ({percentage:.1f}%)")
        
        # Mostrar visualizaciÃ³n t-SNE con los clusters finales
        self._show_final_tsne_visualization(n_clusters)
        
        return kmeans
    
    def _show_final_tsne_visualization(self, n_clusters):
        """
        Muestra visualizaciÃ³n t-SNE con los clusters finales seleccionados por el usuario
        """
        print("ğŸ¨ Generando visualizaciÃ³n t-SNE final...")
        
        # Preparar datos para t-SNE (limitar puntos para eficiencia)
        max_samples = min(self.tsne_samples, len(self.pca_features))
        if len(self.pca_features) > self.tsne_samples:
            sample_indices = np.random.choice(len(self.pca_features), max_samples, replace=False)
            tsne_data = self.pca_features[sample_indices]
            tsne_labels = self.cluster_labels[sample_indices]
            print(f"   ğŸ“Š Usando muestra de {max_samples} puntos de {len(self.pca_features)} total para visualizaciÃ³n")
        else:
            tsne_data = self.pca_features
            tsne_labels = self.cluster_labels
            print(f"   ğŸ“Š Usando todos los {len(self.pca_features)} puntos para visualizaciÃ³n")
        
        try:
            # Aplicar t-SNE
            perplexity_value = min(30, len(tsne_data) - 1)
            tsne = TSNE(n_components=2,  perplexity=perplexity_value)
            tsne_result = tsne.fit_transform(tsne_data)
            
            # Crear figura para la visualizaciÃ³n final
            plt.figure(figsize=(12, 8))
            
            # Crear scatter plot con colores por cluster
            colors = plt.cm.Set3(np.linspace(0, 1, n_clusters))
            
            for cluster_id in range(n_clusters):
                mask = tsne_labels == cluster_id
                if np.any(mask):
                    count = np.sum(mask)
                    plt.scatter(tsne_result[mask, 0], tsne_result[mask, 1], 
                              c=[colors[cluster_id]], 
                              label=f'Cluster {cluster_id} ({count} imÃ¡genes)',
                              alpha=0.7, s=50)
            
            plt.xlabel('t-SNE Componente 1', fontsize=12)
            plt.ylabel('t-SNE Componente 2', fontsize=12)
            
            sample_size = len(tsne_data)
            total_images = len(self.cluster_labels)
            plt.title(f'ğŸª VisualizaciÃ³n Final de Clusters con t-SNE\n'
                     f'Clusters: {n_clusters} | Muestra: {sample_size} de {total_images} imÃ¡genes', 
                     fontsize=14, fontweight='bold')
            
            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            
            # Guardar grÃ¡fico final
            final_tsne_path = "final_tsne_clusters.png"
            plt.savefig(final_tsne_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ VisualizaciÃ³n t-SNE final guardada: {final_tsne_path}")
            
            # Mostrar grÃ¡fico
            plt.show()
            
        except Exception as e:
            print(f"âŒ Error generando t-SNE final: {e}")
            print("   Continuando con el proceso...")
    
    def organize_into_folders(self, copy_files=True):
        """
        Organiza las imÃ¡genes en carpetas por cluster
        """
        print(f"\nğŸ—‚ï¸ ORGANIZANDO IMÃGENES EN CARPETAS")
        print("=" * 40)
        
        if len(self.cluster_labels) == 0:
            print("âŒ Primero ejecuta el clustering")
            return None, None
        
        # Crear carpeta principal de salida
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_dir = f"Clustered_Images_{timestamp}"
        os.makedirs(output_dir, exist_ok=True)
        
        # Crear carpetas para cada cluster
        n_clusters = len(set(self.cluster_labels))
        cluster_folders = {}
        
        for i in range(n_clusters):
            cluster_folder = os.path.join(output_dir, f"cluster_{i}")
            os.makedirs(cluster_folder, exist_ok=True)
            cluster_folders[i] = cluster_folder
            print(f"ğŸ“ Creada carpeta: cluster_{i}")
        
        # Organizar imÃ¡genes
        organized_count = 0
        cluster_stats = {i: {'count': 0, 'sources': Counter(), 'images': []} 
                        for i in range(n_clusters)}
        
        for idx, (img_path, img_name, folder_source, cluster_id) in enumerate(
            zip(self.image_paths, self.image_names, self.folder_labels, self.cluster_labels)):
            
            try:
                # Destino
                dest_folder = cluster_folders[cluster_id]
                
                # Crear nombre Ãºnico para evitar conflictos
                base_name, ext = os.path.splitext(img_name)
                if folder_source != ".":
                    unique_name = f"{folder_source}_{base_name}{ext}"
                else:
                    unique_name = img_name
                dest_path = os.path.join(dest_folder, unique_name)
                
                # Copiar archivo
                if copy_files:
                    shutil.copy2(img_path, dest_path)
                else:
                    shutil.move(img_path, dest_path)
                
                # Actualizar estadÃ­sticas
                cluster_stats[cluster_id]['count'] += 1
                cluster_stats[cluster_id]['sources'][folder_source] += 1
                cluster_stats[cluster_id]['images'].append(unique_name)
                
                organized_count += 1
                
                if organized_count % 500 == 0:
                    print(f"  ğŸ“‹ Organizadas {organized_count:,} imÃ¡genes...")
                    
            except Exception as e:
                print(f"  âŒ Error organizando {img_name}: {e}")
                continue
        
        print(f"\nâœ… Organizadas {organized_count:,} imÃ¡genes en {n_clusters} clusters")
        
        # Generar reporte
        self._generate_report(output_dir, cluster_stats)
        
        # Crear muestras visuales
        self._create_cluster_samples(output_dir, cluster_stats)
        
        return output_dir, cluster_stats
    
    def _generate_report(self, output_dir, cluster_stats):
        """
        Genera reporte detallado de los clusters
        """
        print("ğŸ“Š Generando reporte...")
        
        report_path = os.path.join(output_dir, "clustering_report.txt")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("ğŸ—‚ï¸ REPORTE COMPLETO DE CLUSTERING DE IMÃGENES\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Carpeta de origen: {self.data_folder}\n")
            f.write(f"Total de imÃ¡genes procesadas: {sum(stats['count'] for stats in cluster_stats.values()):,}\n")
            f.write(f"NÃºmero de clusters: {len(cluster_stats)}\n")
            f.write(f"CaracterÃ­sticas extraÃ­das por imagen: {self.image_features.shape[1]}\n")
            f.write(f"Componentes PCA utilizados: {self.pca_features.shape[1]}\n\n")
            
            for cluster_id, stats in cluster_stats.items():
                f.write(f"ğŸ¯ CLUSTER {cluster_id}\n")
                f.write("-" * 40 + "\n")
                f.write(f"Cantidad de imÃ¡genes: {stats['count']:,}\n")
                f.write(f"Porcentaje del total: {(stats['count'] / sum(s['count'] for s in cluster_stats.values())) * 100:.1f}%\n")
                f.write(f"Fuentes de datos:\n")
                
                for source, count in stats['sources'].items():
                    percentage = (count / stats['count']) * 100
                    f.write(f"  - {source}: {count:,} imÃ¡genes ({percentage:.1f}%)\n")
                
                f.write("\n")
        
        print(f"ğŸ“„ Reporte guardado: {report_path}")
    
    def _create_cluster_samples(self, output_dir, cluster_stats, samples_per_cluster=30):
        """
        Crea muestras visuales de cada cluster
        """
        print("ğŸ–¼ï¸ Creando muestras visuales...")
        
        for cluster_id, stats in cluster_stats.items():
            if stats['count'] == 0:
                continue
                
            cluster_folder = os.path.join(output_dir, f"cluster_{cluster_id}")
            sample_images = stats['images'][:samples_per_cluster]
            
            # Crear visualizaciÃ³n de muestra
            fig, axes = plt.subplots(3, 3, figsize=(12, 12))
            fig.suptitle(f'Cluster {cluster_id} - Muestra de {len(sample_images)} imÃ¡genes\n'
                        f'Total: {stats["count"]} imÃ¡genes', 
                        fontsize=16, fontweight='bold')
            
            for i, ax in enumerate(axes.flat):
                if i < len(sample_images):
                    img_path = os.path.join(cluster_folder, sample_images[i])
                    try:
                        img = Image.open(img_path)
                        ax.imshow(img)
                        ax.set_title(sample_images[i][:25] + "..." if len(sample_images[i]) > 25 else sample_images[i], 
                                   fontsize=8)
                    except:
                        ax.text(0.5, 0.5, 'Error\ncargando\nimagen', 
                               ha='center', va='center', transform=ax.transAxes)
                else:
                    ax.axis('off')
                
                ax.set_xticks([])
                ax.set_yticks([])
            
            plt.tight_layout()
            sample_path = os.path.join(output_dir, f"cluster_{cluster_id}_sample.png")
            plt.savefig(sample_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"  ğŸ“¸ Muestra del Cluster {cluster_id}: cluster_{cluster_id}_sample.png")

def main():
    """
    FunciÃ³n principal del script
    """
    # Configurar argumentos de lÃ­nea de comandos
    parser = argparse.ArgumentParser(
        description="Sistema completo de clustering de imÃ¡genes por caracterÃ­sticas de color",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ejemplos de uso:

ANÃLISIS COMPLETO:
  python complete_clustering.py Raw_data
  python complete_clustering.py "C:/Users/Usuario/MisDatos"
  python complete_clustering.py ./imagenes --max-images 1000

ANÃLISIS ÃšNICAMENTE (sin organizaciÃ³n):
  python complete_clustering.py Raw_data --only-analysis
  python complete_clustering.py Raw_data --only-analysis --max-images 500
  python complete_clustering.py Raw_data --only-analysis --tsne-samples 10000

El script realizarÃ¡:

MODO COMPLETO:
1. Carga y anÃ¡lisis de caracterÃ­sticas de color
2. AnÃ¡lisis directo del nÃºmero Ã³ptimo de clusters
3. VisualizaciÃ³n del mÃ©todo del codo y Silhouette
4. Clustering personalizado segÃºn tu elecciÃ³n
5. OrganizaciÃ³n automÃ¡tica en carpetas

MODO ANÃLISIS ÃšNICAMENTE (--only-analysis):
1. Carga y anÃ¡lisis de caracterÃ­sticas de color
2. AnÃ¡lisis de clusters Ã³ptimos (Codo + Silhouette)
3. SelecciÃ³n interactiva del nÃºmero de clusters
4. VisualizaciÃ³n t-SNE con clusters finales
5. NO organiza carpetas ni genera reportes
        """
    )
    
    parser.add_argument('data_folder', 
                       help='Ruta a la carpeta que contiene las imÃ¡genes o subcarpetas con imÃ¡genes')
    parser.add_argument('--max-images', type=int, default=None,
                       help='MÃ¡ximo nÃºmero de imÃ¡genes por carpeta (opcional)')
    parser.add_argument('--no-copy', action='store_true',
                       help='Mover archivos en lugar de copiarlos')
    parser.add_argument('--only-analysis', action='store_true',
                       help='Solo realizar anÃ¡lisis y visualizaciones (sin organizar en carpetas)')
    parser.add_argument('--tsne-samples', type=int, default=5000,
                       help='MÃ¡ximo nÃºmero de puntos para visualizaciÃ³n t-SNE (default: 5000)')
    
    args = parser.parse_args()
    
    # Verificar argumentos
    if not os.path.exists(args.data_folder):
        print(f"âŒ Error: La carpeta '{args.data_folder}' no existe")
        sys.exit(1)
    
    # Verificar argumentos bÃ¡sicos
    # (No hay validaciones adicionales necesarias)
    
    if args.only_analysis:
        print("ğŸ¯ ANÃLISIS ÃšNICAMENTE - SIN ORGANIZACIÃ“N")
        print("=" * 60)
        print("Este script analizarÃ¡ tus imÃ¡genes, mostrarÃ¡ el anÃ¡lisis de clusters")
        print("y generarÃ¡ solo las visualizaciones (sin organizar en carpetas).\n")
    else:
        print("ğŸ¯ SISTEMA COMPLETO DE CLUSTERING DE IMÃGENES")
        print("=" * 60)
        print("Este script analizarÃ¡ tus imÃ¡genes, mostrarÃ¡ el anÃ¡lisis de clusters")
        print("y te permitirÃ¡ elegir el nÃºmero de clusters Ã³ptimo.\n")
    
    try:
        # Crear instancia del sistema
        clustering_system = CompleteImageClustering(args.data_folder, tsne_samples=args.tsne_samples)
        
        # 1. Cargar imÃ¡genes
        clustering_system.load_images(max_images_per_folder=args.max_images)
        
        if len(clustering_system.image_features) == 0:
            print("âŒ No se pudieron cargar imÃ¡genes")
            sys.exit(1)
        
        if args.only_analysis:
            # Modo de anÃ¡lisis Ãºnicamente (sin organizaciÃ³n)
            # 2. Preparar datos y mostrar anÃ¡lisis de clusters
            suggested_k = clustering_system.prepare_data_for_analysis_only()
            
            # 3. Pregunta al usuario (igual que modo completo)
            final_k = clustering_system.ask_user_clusters(suggested_k)
            
            # 4. Clustering final
            kmeans_model = clustering_system.perform_clustering(final_k)
            
            if kmeans_model is None:
                print("âŒ Error en el clustering")
                sys.exit(1)
                
            print(f"\nâœ… Â¡ANÃLISIS ÃšNICAMENTE COMPLETADO!")
            print(f"ğŸ“Š AnÃ¡lisis guardado: cluster_analysis.png")
            print(f"ğŸª VisualizaciÃ³n t-SNE guardada: final_tsne_clusters.png")
            print(f"â„¹ï¸ Nota: No se organizaron carpetas (usa modo completo para eso)")
            
        else:
            # Modo completo original
            # 2. Preparar datos y anÃ¡lisis directo de clusters
            suggested_k = clustering_system.prepare_data_and_analyze_clusters()
            
            # 3. Pregunta al usuario
            final_k = clustering_system.ask_user_clusters(suggested_k)
            
            # 4. Clustering final
            kmeans_model = clustering_system.perform_clustering(final_k)
            
            if kmeans_model is None:
                print("âŒ Error en el clustering")
                sys.exit(1)
            
            # 5. Organizar en carpetas
            output_dir, stats = clustering_system.organize_into_folders(copy_files=not args.no_copy)
            
            if output_dir:
                print(f"\nğŸ‰ Â¡CLUSTERING COMPLETADO EXITOSAMENTE!")
                print(f"ğŸ“ Resultados en: {output_dir}")
                print(f"ğŸ“Š Consulta el reporte y las muestras visuales")
                
                # Mostrar resumen final
                print(f"\nğŸ“Š RESUMEN FINAL:")
                for cluster_id, cluster_stats in stats.items():
                    print(f"  ğŸ¯ Cluster {cluster_id}: {cluster_stats['count']:,} imÃ¡genes")
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ Proceso interrumpido por el usuario")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
